{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c4d7c13-2147-4846-b008-1b83274faaeb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MEstimate Encoding categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "814c9b3f-a144-4833-b72b-12ba6dafd2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string, copy, time\n",
    "import optuna\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from category_encoders import MEstimateEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f2320d-6872-4e46-927c-207947a2cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a390bcf5-9c63-4700-bfcd-a8a5b51d02ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((900000, 33), (700000, 32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cf862d3-03b5-425a-ab68-b39b4cba7a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f_00</th>\n",
       "      <th>f_01</th>\n",
       "      <th>f_02</th>\n",
       "      <th>f_03</th>\n",
       "      <th>f_04</th>\n",
       "      <th>f_05</th>\n",
       "      <th>f_06</th>\n",
       "      <th>f_07</th>\n",
       "      <th>f_08</th>\n",
       "      <th>...</th>\n",
       "      <th>f_22</th>\n",
       "      <th>f_23</th>\n",
       "      <th>f_24</th>\n",
       "      <th>f_25</th>\n",
       "      <th>f_26</th>\n",
       "      <th>f_27</th>\n",
       "      <th>f_28</th>\n",
       "      <th>f_29</th>\n",
       "      <th>f_30</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.373246</td>\n",
       "      <td>0.238887</td>\n",
       "      <td>-0.243376</td>\n",
       "      <td>0.567405</td>\n",
       "      <td>-0.647715</td>\n",
       "      <td>0.839326</td>\n",
       "      <td>0.113133</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.540739</td>\n",
       "      <td>0.766952</td>\n",
       "      <td>-2.730628</td>\n",
       "      <td>-0.208177</td>\n",
       "      <td>1.363402</td>\n",
       "      <td>ABABDADBAB</td>\n",
       "      <td>67.609153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.697021</td>\n",
       "      <td>-1.710322</td>\n",
       "      <td>-2.230332</td>\n",
       "      <td>-0.545661</td>\n",
       "      <td>1.113173</td>\n",
       "      <td>-1.552175</td>\n",
       "      <td>0.447825</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.278315</td>\n",
       "      <td>-0.633658</td>\n",
       "      <td>-1.217077</td>\n",
       "      <td>-3.782194</td>\n",
       "      <td>-0.058316</td>\n",
       "      <td>ACACCADCEB</td>\n",
       "      <td>377.096415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      f_00      f_01      f_02      f_03      f_04      f_05      f_06  \\\n",
       "0   0 -1.373246  0.238887 -0.243376  0.567405 -0.647715  0.839326  0.113133   \n",
       "1   1  1.697021 -1.710322 -2.230332 -0.545661  1.113173 -1.552175  0.447825   \n",
       "\n",
       "   f_07  f_08  ...      f_22      f_23      f_24      f_25      f_26  \\\n",
       "0     1     5  ... -2.540739  0.766952 -2.730628 -0.208177  1.363402   \n",
       "1     1     3  ...  2.278315 -0.633658 -1.217077 -3.782194 -0.058316   \n",
       "\n",
       "         f_27        f_28  f_29  f_30  target  \n",
       "0  ABABDADBAB   67.609153     0     0       0  \n",
       "1  ACACCADCEB  377.096415     0     0       1  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bc7a517-ed11-45c4-a46c-674ecebc1b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(df):\n",
    "    df['i_02_21'] = (df.f_21 + df.f_02 > 5.2).astype(int) - (df.f_21 + df.f_02 < -5.3).astype(int)\n",
    "    df['i_05_22'] = (df.f_22 + df.f_05 > 5.1).astype(int) - (df.f_22 + df.f_05 < -5.4).astype(int)\n",
    "    i_00_01_26 = df.f_00 + df.f_01 + df.f_26\n",
    "    df['i_00_01_26'] = (i_00_01_26 > 5.0).astype(int) - (i_00_01_26 < -5.0).astype(int)\n",
    "    return df\n",
    "\n",
    "train_df = transform_df(train_df)\n",
    "test_df = transform_df(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c649311-828d-4bd7-ac5b-38cee4e586b9",
   "metadata": {},
   "source": [
    "# Splitting feature 27 intelligently\n",
    "\n",
    "By itself, we can see that feature 27 has close to 741k unique values in a train size of 900k entries. However, we can decompose these into a set of columns and then create counts of the alphabets as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8873ea9b-6fb0-4e33-9d85-3fb2338f7de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741354"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.f_27.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf3f2a8d-af4d-4e13-9c13-cd159c22f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a default counter for all the alphabets\n",
    "default_counter = {}\n",
    "for s in string.ascii_uppercase:\n",
    "    default_counter[s] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02ed1b05-03b3-4d96-9cd1-87fb5e558254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get the alphabet counts in each record of the train/test df\n",
    "def get_counts(x):\n",
    "    counts = copy.deepcopy(default_counter)\n",
    "    for letter in x:\n",
    "        counts[letter] += 1\n",
    "    return list(counts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f64b7937-e45a-48f6-953e-f53975d89999",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_alphabet_counts = train_df.f_27.apply(lambda x: get_counts(x))\n",
    "test_alphabet_counts = test_df.f_27.apply(lambda x: get_counts(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48b6146b-767b-4b22-a9ec-a5947c84e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_alphabet_df = pd.DataFrame(np.array(train_alphabet_counts.values.tolist()), columns = list(string.ascii_uppercase))\n",
    "test_alphabet_df = pd.DataFrame(np.array(test_alphabet_counts.values.tolist()), columns = list(string.ascii_uppercase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9627aaa7-0dff-412c-bfa1-c379ed087447",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_alphabet_df = pd.DataFrame(np.array(test_alphabet_counts.values.tolist()), columns = list(string.ascii_uppercase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "229aeb0d-6815-400b-ac13-4ff85a1208cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>2.460909</td>\n",
       "      <td>1.348131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>3.244169</td>\n",
       "      <td>1.422739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>1.478987</td>\n",
       "      <td>1.063639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>1.028972</td>\n",
       "      <td>0.929393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.597529</td>\n",
       "      <td>0.734487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.315301</td>\n",
       "      <td>0.547126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.163871</td>\n",
       "      <td>0.398628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.094059</td>\n",
       "      <td>0.301564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.066087</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.055603</td>\n",
       "      <td>0.230243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.052231</td>\n",
       "      <td>0.222772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.051221</td>\n",
       "      <td>0.220575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.051227</td>\n",
       "      <td>0.220485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.051048</td>\n",
       "      <td>0.220105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.050491</td>\n",
       "      <td>0.218956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.050308</td>\n",
       "      <td>0.218579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.049601</td>\n",
       "      <td>0.217120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.048264</td>\n",
       "      <td>0.214325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.046483</td>\n",
       "      <td>0.210530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.043639</td>\n",
       "      <td>0.204290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z</th>\n",
       "      <td>900000.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count      mean       std  min  25%  50%  75%   max\n",
       "A  900000.0  2.460909  1.348131  0.0  2.0  2.0  3.0   9.0\n",
       "B  900000.0  3.244169  1.422739  0.0  2.0  3.0  4.0  10.0\n",
       "C  900000.0  1.478987  1.063639  0.0  1.0  1.0  2.0   7.0\n",
       "D  900000.0  1.028972  0.929393  0.0  0.0  1.0  2.0   7.0\n",
       "E  900000.0  0.597529  0.734487  0.0  0.0  0.0  1.0   5.0\n",
       "F  900000.0  0.315301  0.547126  0.0  0.0  0.0  1.0   5.0\n",
       "G  900000.0  0.163871  0.398628  0.0  0.0  0.0  0.0   4.0\n",
       "H  900000.0  0.094059  0.301564  0.0  0.0  0.0  0.0   3.0\n",
       "I  900000.0  0.066087  0.251902  0.0  0.0  0.0  0.0   3.0\n",
       "J  900000.0  0.055603  0.230243  0.0  0.0  0.0  0.0   3.0\n",
       "K  900000.0  0.052231  0.222772  0.0  0.0  0.0  0.0   2.0\n",
       "L  900000.0  0.051221  0.220575  0.0  0.0  0.0  0.0   2.0\n",
       "M  900000.0  0.051227  0.220485  0.0  0.0  0.0  0.0   2.0\n",
       "N  900000.0  0.051048  0.220105  0.0  0.0  0.0  0.0   2.0\n",
       "O  900000.0  0.050491  0.218956  0.0  0.0  0.0  0.0   1.0\n",
       "P  900000.0  0.050308  0.218579  0.0  0.0  0.0  0.0   1.0\n",
       "Q  900000.0  0.049601  0.217120  0.0  0.0  0.0  0.0   1.0\n",
       "R  900000.0  0.048264  0.214325  0.0  0.0  0.0  0.0   1.0\n",
       "S  900000.0  0.046483  0.210530  0.0  0.0  0.0  0.0   1.0\n",
       "T  900000.0  0.043639  0.204290  0.0  0.0  0.0  0.0   1.0\n",
       "U  900000.0  0.000000  0.000000  0.0  0.0  0.0  0.0   0.0\n",
       "V  900000.0  0.000000  0.000000  0.0  0.0  0.0  0.0   0.0\n",
       "W  900000.0  0.000000  0.000000  0.0  0.0  0.0  0.0   0.0\n",
       "X  900000.0  0.000000  0.000000  0.0  0.0  0.0  0.0   0.0\n",
       "Y  900000.0  0.000000  0.000000  0.0  0.0  0.0  0.0   0.0\n",
       "Z  900000.0  0.000000  0.000000  0.0  0.0  0.0  0.0   0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_alphabet_df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a1ba07-21b8-4cdb-b2ed-ea6bc0850df4",
   "metadata": {},
   "source": [
    "We can see that `U, V, W, X, Y, Z` never appear in the corpus. Only upto T, we find some representation of these alphabets in our feature, so we will only keep these counts till alphabet T in our corpus and add them to the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e598e2e-78fa-444a-992f-38c43c85e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, train_alphabet_df.iloc[:, :20]], axis = 1)\n",
    "test_df = pd.concat([test_df, test_alphabet_df.iloc[:, :20]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a66d6d9-0524-487c-9aff-488a1f8681b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f_00</th>\n",
       "      <th>f_01</th>\n",
       "      <th>f_02</th>\n",
       "      <th>f_03</th>\n",
       "      <th>f_04</th>\n",
       "      <th>f_05</th>\n",
       "      <th>f_06</th>\n",
       "      <th>f_07</th>\n",
       "      <th>f_08</th>\n",
       "      <th>...</th>\n",
       "      <th>K</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>N</th>\n",
       "      <th>O</th>\n",
       "      <th>P</th>\n",
       "      <th>Q</th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.373246</td>\n",
       "      <td>0.238887</td>\n",
       "      <td>-0.243376</td>\n",
       "      <td>0.567405</td>\n",
       "      <td>-0.647715</td>\n",
       "      <td>0.839326</td>\n",
       "      <td>0.113133</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.697021</td>\n",
       "      <td>-1.710322</td>\n",
       "      <td>-2.230332</td>\n",
       "      <td>-0.545661</td>\n",
       "      <td>1.113173</td>\n",
       "      <td>-1.552175</td>\n",
       "      <td>0.447825</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.681726</td>\n",
       "      <td>0.616746</td>\n",
       "      <td>-1.027689</td>\n",
       "      <td>0.810492</td>\n",
       "      <td>-0.609086</td>\n",
       "      <td>0.113965</td>\n",
       "      <td>-0.708660</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      f_00      f_01      f_02      f_03      f_04      f_05      f_06  \\\n",
       "0   0 -1.373246  0.238887 -0.243376  0.567405 -0.647715  0.839326  0.113133   \n",
       "1   1  1.697021 -1.710322 -2.230332 -0.545661  1.113173 -1.552175  0.447825   \n",
       "2   2  1.681726  0.616746 -1.027689  0.810492 -0.609086  0.113965 -0.708660   \n",
       "\n",
       "   f_07  f_08  ...  K  L  M  N  O  P  Q  R  S  T  \n",
       "0     1     5  ...  0  0  0  0  0  0  0  0  0  0  \n",
       "1     1     3  ...  0  0  0  0  0  0  0  0  0  0  \n",
       "2     1     0  ...  1  0  0  0  0  0  0  0  0  0  \n",
       "\n",
       "[3 rows x 56 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d47cfb3-30b5-4111-bd1e-b90cc380a663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f_00</th>\n",
       "      <th>f_01</th>\n",
       "      <th>f_02</th>\n",
       "      <th>f_03</th>\n",
       "      <th>f_04</th>\n",
       "      <th>f_05</th>\n",
       "      <th>f_06</th>\n",
       "      <th>f_07</th>\n",
       "      <th>f_08</th>\n",
       "      <th>...</th>\n",
       "      <th>K</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>N</th>\n",
       "      <th>O</th>\n",
       "      <th>P</th>\n",
       "      <th>Q</th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>900000</td>\n",
       "      <td>0.442517</td>\n",
       "      <td>0.174380</td>\n",
       "      <td>-0.999816</td>\n",
       "      <td>0.762741</td>\n",
       "      <td>0.186778</td>\n",
       "      <td>-1.074775</td>\n",
       "      <td>0.501888</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>900001</td>\n",
       "      <td>-0.605598</td>\n",
       "      <td>-0.305715</td>\n",
       "      <td>0.627667</td>\n",
       "      <td>-0.578898</td>\n",
       "      <td>-1.750931</td>\n",
       "      <td>1.355550</td>\n",
       "      <td>-0.190911</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>900002</td>\n",
       "      <td>0.303990</td>\n",
       "      <td>2.445110</td>\n",
       "      <td>0.246515</td>\n",
       "      <td>0.818248</td>\n",
       "      <td>0.359731</td>\n",
       "      <td>-1.331845</td>\n",
       "      <td>1.358622</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id      f_00      f_01      f_02      f_03      f_04      f_05  \\\n",
       "0  900000  0.442517  0.174380 -0.999816  0.762741  0.186778 -1.074775   \n",
       "1  900001 -0.605598 -0.305715  0.627667 -0.578898 -1.750931  1.355550   \n",
       "2  900002  0.303990  2.445110  0.246515  0.818248  0.359731 -1.331845   \n",
       "\n",
       "       f_06  f_07  f_08  ...  K  L  M  N  O  P  Q  R  S  T  \n",
       "0  0.501888     6     6  ...  0  1  0  0  0  0  0  0  0  0  \n",
       "1 -0.190911     1     3  ...  0  0  0  0  0  0  0  0  0  0  \n",
       "2  1.358622     3     3  ...  1  0  0  0  0  0  0  0  0  0  \n",
       "\n",
       "[3 rows x 55 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c172c55-6cf3-4252-9e77-19872d0381a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(columns = [\"f_27\", \"id\"], inplace = True)\n",
    "test_ids = test_df[\"id\"]\n",
    "test_df.drop(columns = [\"f_27\", \"id\"], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0cc364-3dc4-4ec1-a547-b957f04ed820",
   "metadata": {},
   "source": [
    "## Fit the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1bc5a0a-d04d-4f5a-ae8e-cce047fe7bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df.pop(\"target\")\n",
    "X = train_df\n",
    "X_train_enc, X_encode, y_train_enc, y_encode = train_test_split(X, y, test_size = 0.2, random_state = 257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67bb7d84-fcca-45fc-b436-e12f2d855add",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [f\"f_{fnum:0>2d}\" for fnum in range(7, 19)] + [\"f_29\" , \"f_30\"]\n",
    "num_cols = [y for y in X_train_enc.columns if (not y in cat_cols) and (y != \"id\") and (y != \"f_27\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2aa4f08c-d069-40ab-88f6-7f682d53244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = MEstimateEncoder(cols = cat_cols, m = 1.5)\n",
    "encoder.fit(X_encode, y_encode);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d316c0c3-01dc-46dc-b126-877ed846b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enc = encoder.transform(X_train_enc)\n",
    "X_encode = encoder.transform(X_encode)\n",
    "X_test = encoder.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e9a576a-38a7-4c9c-9639-fc441ba15778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((620000, 53), (620000,), (100000, 53), (100000,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_enc, y_train_enc, stratify = y_train_enc, test_size = 100000, random_state = 121)\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39affa4a-cced-43b2-9014-76abaf961c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    318308\n",
       "1    301692\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3bb8964-5534-4142-b52f-aca08f40fbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_00</th>\n",
       "      <th>f_01</th>\n",
       "      <th>f_02</th>\n",
       "      <th>f_03</th>\n",
       "      <th>f_04</th>\n",
       "      <th>f_05</th>\n",
       "      <th>f_06</th>\n",
       "      <th>f_07</th>\n",
       "      <th>f_08</th>\n",
       "      <th>f_09</th>\n",
       "      <th>...</th>\n",
       "      <th>K</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>N</th>\n",
       "      <th>O</th>\n",
       "      <th>P</th>\n",
       "      <th>Q</th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229487</th>\n",
       "      <td>0.703040</td>\n",
       "      <td>1.246406</td>\n",
       "      <td>0.160750</td>\n",
       "      <td>-1.129079</td>\n",
       "      <td>0.415793</td>\n",
       "      <td>0.437626</td>\n",
       "      <td>-0.520668</td>\n",
       "      <td>0.480970</td>\n",
       "      <td>0.482350</td>\n",
       "      <td>0.500603</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614596</th>\n",
       "      <td>0.478763</td>\n",
       "      <td>-0.316379</td>\n",
       "      <td>1.470314</td>\n",
       "      <td>0.401741</td>\n",
       "      <td>-1.752594</td>\n",
       "      <td>-0.294004</td>\n",
       "      <td>-0.927445</td>\n",
       "      <td>0.491573</td>\n",
       "      <td>0.506162</td>\n",
       "      <td>0.518572</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            f_00      f_01      f_02      f_03      f_04      f_05      f_06  \\\n",
       "229487  0.703040  1.246406  0.160750 -1.129079  0.415793  0.437626 -0.520668   \n",
       "614596  0.478763 -0.316379  1.470314  0.401741 -1.752594 -0.294004 -0.927445   \n",
       "\n",
       "            f_07      f_08      f_09  ...  K  L  M  N  O  P  Q  R  S  T  \n",
       "229487  0.480970  0.482350  0.500603  ...  0  0  0  0  0  0  1  0  0  0  \n",
       "614596  0.491573  0.506162  0.518572  ...  0  0  0  0  0  0  0  0  0  0  \n",
       "\n",
       "[2 rows x 53 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enc.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d76b9e9-22eb-4609-a382-77bc80a99a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "    \n",
    "    param = {\n",
    "        \"verbosity\": 0,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1.0, 2.0, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 9, step=2),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500, step=50)\n",
    "    }\n",
    "\n",
    "    bst = xgb.train(param, dtrain)\n",
    "    preds = bst.predict(dvalid)\n",
    "    \n",
    "    met = roc_auc_score(y_valid, preds)\n",
    "    return met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ef03cc0-dd46-42ca-bdc9-6be4b5c86616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-05-30 07:35:03,031]\u001b[0m A new study created in memory with name: no-name-42298cda-787f-4658-9a90-50eb1ac35d3c\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:35:08,050]\u001b[0m Trial 0 finished with value: 0.7774526846161987 and parameters: {'lambda': 1.3650632584842113, 'max_depth': 3, 'n_estimators': 150}. Best is trial 0 with value: 0.7774526846161987.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:35:18,075]\u001b[0m Trial 1 finished with value: 0.8771892035735747 and parameters: {'lambda': 1.0375935776266463, 'max_depth': 7, 'n_estimators': 300}. Best is trial 1 with value: 0.8771892035735747.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:35:30,716]\u001b[0m Trial 2 finished with value: 0.9037721663207382 and parameters: {'lambda': 1.2918122375900758, 'max_depth': 9, 'n_estimators': 150}. Best is trial 2 with value: 0.9037721663207382.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:35:40,683]\u001b[0m Trial 3 finished with value: 0.8767376540526468 and parameters: {'lambda': 1.239128387261953, 'max_depth': 7, 'n_estimators': 150}. Best is trial 2 with value: 0.9037721663207382.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:35:50,651]\u001b[0m Trial 4 finished with value: 0.8770195343103231 and parameters: {'lambda': 1.441349833366168, 'max_depth': 7, 'n_estimators': 100}. Best is trial 2 with value: 0.9037721663207382.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:35:57,926]\u001b[0m Trial 5 finished with value: 0.8334950344735602 and parameters: {'lambda': 1.3858692612334873, 'max_depth': 5, 'n_estimators': 400}. Best is trial 2 with value: 0.9037721663207382.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:36:10,881]\u001b[0m Trial 6 finished with value: 0.90003146439899 and parameters: {'lambda': 1.3295783279758575, 'max_depth': 9, 'n_estimators': 350}. Best is trial 2 with value: 0.9037721663207382.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:36:20,854]\u001b[0m Trial 7 finished with value: 0.8771701458855807 and parameters: {'lambda': 1.0768624935434494, 'max_depth': 7, 'n_estimators': 350}. Best is trial 2 with value: 0.9037721663207382.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:36:25,833]\u001b[0m Trial 8 finished with value: 0.7774276026012924 and parameters: {'lambda': 1.4823321453333238, 'max_depth': 3, 'n_estimators': 450}. Best is trial 2 with value: 0.9037721663207382.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:36:38,714]\u001b[0m Trial 9 finished with value: 0.9038172771211195 and parameters: {'lambda': 1.2435233159739043, 'max_depth': 9, 'n_estimators': 500}. Best is trial 9 with value: 0.9038172771211195.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:36:51,479]\u001b[0m Trial 10 finished with value: 0.9035458992066463 and parameters: {'lambda': 1.7879699610799251, 'max_depth': 9, 'n_estimators': 500}. Best is trial 9 with value: 0.9038172771211195.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:37:04,187]\u001b[0m Trial 11 finished with value: 0.9037359050764622 and parameters: {'lambda': 1.1765865851568973, 'max_depth': 9, 'n_estimators': 250}. Best is trial 9 with value: 0.9038172771211195.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:37:17,109]\u001b[0m Trial 12 finished with value: 0.899888693655331 and parameters: {'lambda': 1.623485290902949, 'max_depth': 9, 'n_estimators': 250}. Best is trial 9 with value: 0.9038172771211195.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:37:23,759]\u001b[0m Trial 13 finished with value: 0.833467251318587 and parameters: {'lambda': 1.1773363926814724, 'max_depth': 5, 'n_estimators': 500}. Best is trial 9 with value: 0.9038172771211195.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:37:33,674]\u001b[0m Trial 14 finished with value: 0.9044345648818807 and parameters: {'lambda': 1.952370228637287, 'max_depth': 9, 'n_estimators': 200}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:37:46,374]\u001b[0m Trial 15 finished with value: 0.9005378533077597 and parameters: {'lambda': 1.997725576537406, 'max_depth': 9, 'n_estimators': 250}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:37:53,661]\u001b[0m Trial 16 finished with value: 0.8334853122906997 and parameters: {'lambda': 1.622874176525373, 'max_depth': 5, 'n_estimators': 200}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:38:02,294]\u001b[0m Trial 17 finished with value: 0.8769082599886544 and parameters: {'lambda': 1.9888565601428756, 'max_depth': 7, 'n_estimators': 400}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:38:12,013]\u001b[0m Trial 18 finished with value: 0.9018309778815536 and parameters: {'lambda': 1.6001580612954773, 'max_depth': 9, 'n_estimators': 200}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:38:19,640]\u001b[0m Trial 19 finished with value: 0.8769232813776167 and parameters: {'lambda': 1.860938174315816, 'max_depth': 7, 'n_estimators': 300}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:38:29,649]\u001b[0m Trial 20 finished with value: 0.9038384771478266 and parameters: {'lambda': 1.1219127471593422, 'max_depth': 9, 'n_estimators': 450}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:38:41,442]\u001b[0m Trial 21 finished with value: 0.9038376331416277 and parameters: {'lambda': 1.1350630661542955, 'max_depth': 9, 'n_estimators': 450}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:38:54,273]\u001b[0m Trial 22 finished with value: 0.9037343895879777 and parameters: {'lambda': 1.1108052418768912, 'max_depth': 9, 'n_estimators': 450}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:39:07,172]\u001b[0m Trial 23 finished with value: 0.9037901706521693 and parameters: {'lambda': 1.0138076510262368, 'max_depth': 9, 'n_estimators': 450}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:39:17,255]\u001b[0m Trial 24 finished with value: 0.8768111844651302 and parameters: {'lambda': 1.1695039988459297, 'max_depth': 7, 'n_estimators': 400}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:39:30,167]\u001b[0m Trial 25 finished with value: 0.9037383588388525 and parameters: {'lambda': 1.108152953382641, 'max_depth': 9, 'n_estimators': 350}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:39:40,119]\u001b[0m Trial 26 finished with value: 0.876950604201962 and parameters: {'lambda': 1.5267783692042065, 'max_depth': 7, 'n_estimators': 450}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:39:53,070]\u001b[0m Trial 27 finished with value: 0.9035269776164032 and parameters: {'lambda': 1.7785605337492902, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:40:00,358]\u001b[0m Trial 28 finished with value: 0.8334658787327411 and parameters: {'lambda': 1.2539505391789827, 'max_depth': 5, 'n_estimators': 400}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:40:05,315]\u001b[0m Trial 29 finished with value: 0.7774512563903897 and parameters: {'lambda': 1.0552659859147984, 'max_depth': 3, 'n_estimators': 300}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:40:18,094]\u001b[0m Trial 30 finished with value: 0.9037590823232878 and parameters: {'lambda': 1.1461303977497432, 'max_depth': 9, 'n_estimators': 200}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:40:30,853]\u001b[0m Trial 31 finished with value: 0.9038200030790114 and parameters: {'lambda': 1.228345029685862, 'max_depth': 9, 'n_estimators': 500}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:40:43,643]\u001b[0m Trial 32 finished with value: 0.9037489204246056 and parameters: {'lambda': 1.209870074004038, 'max_depth': 9, 'n_estimators': 500}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:40:56,425]\u001b[0m Trial 33 finished with value: 0.9038106039281654 and parameters: {'lambda': 1.3441139930300143, 'max_depth': 9, 'n_estimators': 450}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:41:06,498]\u001b[0m Trial 34 finished with value: 0.8767323024088822 and parameters: {'lambda': 1.2925099112972376, 'max_depth': 7, 'n_estimators': 500}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:41:19,169]\u001b[0m Trial 35 finished with value: 0.9037304461556468 and parameters: {'lambda': 1.00969159112094, 'max_depth': 9, 'n_estimators': 450}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:41:29,241]\u001b[0m Trial 36 finished with value: 0.8768116363897206 and parameters: {'lambda': 1.1105221479016714, 'max_depth': 7, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:41:41,864]\u001b[0m Trial 37 finished with value: 0.9038096320301093 and parameters: {'lambda': 1.0630732910992162, 'max_depth': 9, 'n_estimators': 400}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:41:51,800]\u001b[0m Trial 38 finished with value: 0.8770206945436492 and parameters: {'lambda': 1.4173023088186567, 'max_depth': 7, 'n_estimators': 350}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:42:04,572]\u001b[0m Trial 39 finished with value: 0.9038374285947139 and parameters: {'lambda': 1.139135145180132, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:42:17,315]\u001b[0m Trial 40 finished with value: 0.900027290200914 and parameters: {'lambda': 1.311945528399031, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:42:30,048]\u001b[0m Trial 41 finished with value: 0.9038381296982744 and parameters: {'lambda': 1.1282240397487535, 'max_depth': 9, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:42:42,868]\u001b[0m Trial 42 finished with value: 0.9038374742274891 and parameters: {'lambda': 1.1380611598608972, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:42:55,566]\u001b[0m Trial 43 finished with value: 0.9038337737696722 and parameters: {'lambda': 1.0892983879648837, 'max_depth': 9, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:43:08,430]\u001b[0m Trial 44 finished with value: 0.9038025373344151 and parameters: {'lambda': 1.0374790758266117, 'max_depth': 9, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:43:21,136]\u001b[0m Trial 45 finished with value: 0.903797467693196 and parameters: {'lambda': 1.264382420197184, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:43:31,148]\u001b[0m Trial 46 finished with value: 0.8768033406313752 and parameters: {'lambda': 1.1987852557262166, 'max_depth': 7, 'n_estimators': 200}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:43:43,993]\u001b[0m Trial 47 finished with value: 0.9038381268962619 and parameters: {'lambda': 1.1281355527233798, 'max_depth': 9, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:43:56,782]\u001b[0m Trial 48 finished with value: 0.9037115752017729 and parameters: {'lambda': 1.3613073665134967, 'max_depth': 9, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:44:08,790]\u001b[0m Trial 49 finished with value: 0.9036771923066023 and parameters: {'lambda': 1.724030302548256, 'max_depth': 9, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:44:14,428]\u001b[0m Trial 50 finished with value: 0.833493245188424 and parameters: {'lambda': 1.4996339036128226, 'max_depth': 5, 'n_estimators': 200}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:44:24,141]\u001b[0m Trial 51 finished with value: 0.9037621889545948 and parameters: {'lambda': 1.1504605137891901, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:44:33,831]\u001b[0m Trial 52 finished with value: 0.9038382063533312 and parameters: {'lambda': 1.1258470635742575, 'max_depth': 9, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:44:43,517]\u001b[0m Trial 53 finished with value: 0.9038337821757099 and parameters: {'lambda': 1.0890904012886753, 'max_depth': 9, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:44:53,224]\u001b[0m Trial 54 finished with value: 0.9038060254397118 and parameters: {'lambda': 1.049510421051064, 'max_depth': 9, 'n_estimators': 250}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:45:04,449]\u001b[0m Trial 55 finished with value: 0.9037350640724193 and parameters: {'lambda': 1.1802767428290342, 'max_depth': 9, 'n_estimators': 200}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:45:17,093]\u001b[0m Trial 56 finished with value: 0.9037383846573963 and parameters: {'lambda': 1.107760913651509, 'max_depth': 9, 'n_estimators': 250}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:45:28,563]\u001b[0m Trial 57 finished with value: 0.9038024044389643 and parameters: {'lambda': 1.030171142331745, 'max_depth': 9, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:45:32,403]\u001b[0m Trial 58 finished with value: 0.7774517127181426 and parameters: {'lambda': 1.213267188258624, 'max_depth': 3, 'n_estimators': 200}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:45:40,039]\u001b[0m Trial 59 finished with value: 0.8771708850164541 and parameters: {'lambda': 1.0718953514997986, 'max_depth': 7, 'n_estimators': 300}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:45:49,782]\u001b[0m Trial 60 finished with value: 0.9035807698521385 and parameters: {'lambda': 1.8967972192452651, 'max_depth': 9, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:45:59,474]\u001b[0m Trial 61 finished with value: 0.9038376769731091 and parameters: {'lambda': 1.1341479762809397, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:46:09,159]\u001b[0m Trial 62 finished with value: 0.9038381595196935 and parameters: {'lambda': 1.1267255295204972, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:46:18,855]\u001b[0m Trial 63 finished with value: 0.9037784994694589 and parameters: {'lambda': 1.1671158475965542, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:46:28,537]\u001b[0m Trial 64 finished with value: 0.9037343319465774 and parameters: {'lambda': 1.1119954566488335, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:46:38,202]\u001b[0m Trial 65 finished with value: 0.9037082508140648 and parameters: {'lambda': 1.1889873716046817, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:46:47,890]\u001b[0m Trial 66 finished with value: 0.9037974004448955 and parameters: {'lambda': 1.2656694116880653, 'max_depth': 9, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:46:57,630]\u001b[0m Trial 67 finished with value: 0.8998851246919588 and parameters: {'lambda': 1.5706702556606358, 'max_depth': 9, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:47:07,285]\u001b[0m Trial 68 finished with value: 0.9038568707588538 and parameters: {'lambda': 1.082417309280185, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:47:14,906]\u001b[0m Trial 69 finished with value: 0.8771952681293812 and parameters: {'lambda': 1.0029453864046909, 'max_depth': 7, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:47:24,574]\u001b[0m Trial 70 finished with value: 0.9038326135363464 and parameters: {'lambda': 1.085223187639655, 'max_depth': 9, 'n_estimators': 200}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:47:34,242]\u001b[0m Trial 71 finished with value: 0.9038379289540921 and parameters: {'lambda': 1.1300021516887333, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:47:43,936]\u001b[0m Trial 72 finished with value: 0.9038385690138085 and parameters: {'lambda': 1.1205090712177805, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:47:53,603]\u001b[0m Trial 73 finished with value: 0.9037640631006814 and parameters: {'lambda': 1.1661626132549494, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:48:03,284]\u001b[0m Trial 74 finished with value: 0.9038194436772267 and parameters: {'lambda': 1.2271190036922452, 'max_depth': 9, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:48:12,970]\u001b[0m Trial 75 finished with value: 0.9039043324477374 and parameters: {'lambda': 1.0978217699765582, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:48:22,656]\u001b[0m Trial 76 finished with value: 0.9036482927497846 and parameters: {'lambda': 1.6937071612071708, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:48:32,364]\u001b[0m Trial 77 finished with value: 0.9037885274719715 and parameters: {'lambda': 1.0270019555427121, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:48:42,029]\u001b[0m Trial 78 finished with value: 0.9038040003852368 and parameters: {'lambda': 1.059524250780753, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:48:47,648]\u001b[0m Trial 79 finished with value: 0.8334690956432549 and parameters: {'lambda': 1.0961953168490897, 'max_depth': 5, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:48:55,258]\u001b[0m Trial 80 finished with value: 0.8771707174961344 and parameters: {'lambda': 1.0741094465206438, 'max_depth': 7, 'n_estimators': 350}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:49:04,956]\u001b[0m Trial 81 finished with value: 0.903738418681834 and parameters: {'lambda': 1.1072856967184326, 'max_depth': 9, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:49:14,625]\u001b[0m Trial 82 finished with value: 0.9038384437238202 and parameters: {'lambda': 1.1223201392233737, 'max_depth': 9, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:49:24,312]\u001b[0m Trial 83 finished with value: 0.9037643058750516 and parameters: {'lambda': 1.162944707131616, 'max_depth': 9, 'n_estimators': 250}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:49:33,987]\u001b[0m Trial 84 finished with value: 0.9038043374273138 and parameters: {'lambda': 1.0539339401794787, 'max_depth': 9, 'n_estimators': 200}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:49:43,658]\u001b[0m Trial 85 finished with value: 0.9038416694406591 and parameters: {'lambda': 1.1174076372043429, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:49:53,342]\u001b[0m Trial 86 finished with value: 0.9038532837825439 and parameters: {'lambda': 1.0750513854693893, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:50:03,017]\u001b[0m Trial 87 finished with value: 0.9037898508224548 and parameters: {'lambda': 1.0202852686233008, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:50:12,710]\u001b[0m Trial 88 finished with value: 0.9038013042487636 and parameters: {'lambda': 1.0452028979187176, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:50:22,394]\u001b[0m Trial 89 finished with value: 0.9002348004430702 and parameters: {'lambda': 1.4435402298580557, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:50:32,071]\u001b[0m Trial 90 finished with value: 0.9037508888383994 and parameters: {'lambda': 1.149666522240441, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:50:41,750]\u001b[0m Trial 91 finished with value: 0.9038570995231615 and parameters: {'lambda': 1.0781483236135077, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:50:51,416]\u001b[0m Trial 92 finished with value: 0.9037343927902777 and parameters: {'lambda': 1.1007125234324726, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:51:01,101]\u001b[0m Trial 93 finished with value: 0.9038032198246069 and parameters: {'lambda': 1.0677008107158037, 'max_depth': 9, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:51:10,773]\u001b[0m Trial 94 finished with value: 0.9038090440077682 and parameters: {'lambda': 1.0731736519207749, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:51:20,448]\u001b[0m Trial 95 finished with value: 0.9038416766458341 and parameters: {'lambda': 1.117182354749418, 'max_depth': 9, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:51:30,138]\u001b[0m Trial 96 finished with value: 0.903791149955544 and parameters: {'lambda': 1.0363045006595533, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:51:39,809]\u001b[0m Trial 97 finished with value: 0.9038325588971022 and parameters: {'lambda': 1.08678214491185, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:51:49,488]\u001b[0m Trial 98 finished with value: 0.9037620184321187 and parameters: {'lambda': 1.1526371485597229, 'max_depth': 9, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:51:59,169]\u001b[0m Trial 99 finished with value: 0.9037042337288335 and parameters: {'lambda': 1.1963753708780118, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:52:08,893]\u001b[0m Trial 100 finished with value: 0.9034355937808771 and parameters: {'lambda': 1.8482668718662705, 'max_depth': 9, 'n_estimators': 200}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:52:18,577]\u001b[0m Trial 101 finished with value: 0.9038384907576018 and parameters: {'lambda': 1.12163284962799, 'max_depth': 9, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:52:28,260]\u001b[0m Trial 102 finished with value: 0.9038416514277214 and parameters: {'lambda': 1.1182477827755495, 'max_depth': 9, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:52:37,923]\u001b[0m Trial 103 finished with value: 0.9038375955146024 and parameters: {'lambda': 1.0928052281233007, 'max_depth': 9, 'n_estimators': 150}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:52:47,591]\u001b[0m Trial 104 finished with value: 0.9038569900445297 and parameters: {'lambda': 1.0808676995252715, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:52:57,266]\u001b[0m Trial 105 finished with value: 0.9038060634670246 and parameters: {'lambda': 1.0491721710800956, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:53:06,952]\u001b[0m Trial 106 finished with value: 0.9038532343470375 and parameters: {'lambda': 1.0755349848918219, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:53:16,613]\u001b[0m Trial 107 finished with value: 0.9038569562202355 and parameters: {'lambda': 1.077212889098499, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:53:26,296]\u001b[0m Trial 108 finished with value: 0.9037901994728694 and parameters: {'lambda': 1.0133114469200304, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:53:35,980]\u001b[0m Trial 109 finished with value: 0.903857020266236 and parameters: {'lambda': 1.0798967613618944, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:53:45,634]\u001b[0m Trial 110 finished with value: 0.9038569488149168 and parameters: {'lambda': 1.0777850893287118, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:53:55,325]\u001b[0m Trial 111 finished with value: 0.9038367350966158 and parameters: {'lambda': 1.0833621272626204, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:54:04,994]\u001b[0m Trial 112 finished with value: 0.903809490728621 and parameters: {'lambda': 1.0650656375178946, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:54:14,667]\u001b[0m Trial 113 finished with value: 0.9038025273272274 and parameters: {'lambda': 1.0379264966866442, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:54:24,354]\u001b[0m Trial 114 finished with value: 0.9038570859133865 and parameters: {'lambda': 1.0787355985465885, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:54:34,030]\u001b[0m Trial 115 finished with value: 0.9038039859748866 and parameters: {'lambda': 1.0602609682574582, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:54:43,703]\u001b[0m Trial 116 finished with value: 0.9038570216672422 and parameters: {'lambda': 1.080171628133694, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:54:53,382]\u001b[0m Trial 117 finished with value: 0.9038570923179864 and parameters: {'lambda': 1.0783546646660889, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:55:03,104]\u001b[0m Trial 118 finished with value: 0.903839131017462 and parameters: {'lambda': 1.0955285212150252, 'max_depth': 9, 'n_estimators': 100}. Best is trial 14 with value: 0.9044345648818807.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:55:12,836]\u001b[0m Trial 119 finished with value: 0.9044345923015746 and parameters: {'lambda': 1.9519759861232213, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:55:18,454]\u001b[0m Trial 120 finished with value: 0.8334800012761165 and parameters: {'lambda': 1.9124665766192823, 'max_depth': 5, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:55:28,132]\u001b[0m Trial 121 finished with value: 0.900517013339661 and parameters: {'lambda': 1.9811840033724348, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:55:37,876]\u001b[0m Trial 122 finished with value: 0.9036366365778556 and parameters: {'lambda': 1.9405669883054781, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:55:47,553]\u001b[0m Trial 123 finished with value: 0.9038025241249275 and parameters: {'lambda': 1.028161970763931, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:55:57,214]\u001b[0m Trial 124 finished with value: 0.9038568457408849 and parameters: {'lambda': 1.0828532379287794, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:56:06,891]\u001b[0m Trial 125 finished with value: 0.9038060042244741 and parameters: {'lambda': 1.049904781576694, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:56:16,556]\u001b[0m Trial 126 finished with value: 0.9037343987945902 and parameters: {'lambda': 1.100547400338591, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:56:26,309]\u001b[0m Trial 127 finished with value: 0.9034357384848093 and parameters: {'lambda': 1.8464271115666502, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:56:36,023]\u001b[0m Trial 128 finished with value: 0.9018741436849602 and parameters: {'lambda': 1.969697193537199, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:56:45,695]\u001b[0m Trial 129 finished with value: 0.9038773158433313 and parameters: {'lambda': 1.0004548567818672, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:56:55,377]\u001b[0m Trial 130 finished with value: 0.9038894445546569 and parameters: {'lambda': 1.0081590970856718, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:57:05,057]\u001b[0m Trial 131 finished with value: 0.9037448727173805 and parameters: {'lambda': 1.0103342704405238, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:57:14,734]\u001b[0m Trial 132 finished with value: 0.903877239588562 and parameters: {'lambda': 1.0021729768256045, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:57:24,417]\u001b[0m Trial 133 finished with value: 0.9037390673477319 and parameters: {'lambda': 1.0024707597288276, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:57:34,089]\u001b[0m Trial 134 finished with value: 0.9037900285501059 and parameters: {'lambda': 1.0170001213897344, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:57:43,790]\u001b[0m Trial 135 finished with value: 0.9037909384035989 and parameters: {'lambda': 1.025288138110678, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:57:53,464]\u001b[0m Trial 136 finished with value: 0.9038029454275238 and parameters: {'lambda': 1.0419917866636714, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:58:03,146]\u001b[0m Trial 137 finished with value: 0.903880746907659 and parameters: {'lambda': 1.0030745129613963, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:58:12,890]\u001b[0m Trial 138 finished with value: 0.9033863736289953 and parameters: {'lambda': 1.8031895676175245, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:58:22,569]\u001b[0m Trial 139 finished with value: 0.9038030082726617 and parameters: {'lambda': 1.0296342286558768, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:58:26,404]\u001b[0m Trial 140 finished with value: 0.7774510286268009 and parameters: {'lambda': 1.0077610063673788, 'max_depth': 3, 'n_estimators': 300}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:58:36,101]\u001b[0m Trial 141 finished with value: 0.9038040938523684 and parameters: {'lambda': 1.0581546150710428, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:58:45,773]\u001b[0m Trial 142 finished with value: 0.9038030248845932 and parameters: {'lambda': 1.0409952285099382, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:58:55,464]\u001b[0m Trial 143 finished with value: 0.9038772227764871 and parameters: {'lambda': 1.0025551612185881, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:59:05,137]\u001b[0m Trial 144 finished with value: 0.9038807096809213 and parameters: {'lambda': 1.003762038371011, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:59:14,829]\u001b[0m Trial 145 finished with value: 0.9037897883776043 and parameters: {'lambda': 1.0219399169019232, 'max_depth': 9, 'n_estimators': 100}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:59:24,514]\u001b[0m Trial 146 finished with value: 0.9038773444638878 and parameters: {'lambda': 1.0000400070576796, 'max_depth': 9, 'n_estimators': 150}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:59:34,193]\u001b[0m Trial 147 finished with value: 0.9037390903642633 and parameters: {'lambda': 1.0020083262321187, 'max_depth': 9, 'n_estimators': 150}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:59:43,866]\u001b[0m Trial 148 finished with value: 0.9038772648066749 and parameters: {'lambda': 1.00158927661801, 'max_depth': 9, 'n_estimators': 150}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n",
      "\u001b[32m[I 2022-05-30 07:59:53,566]\u001b[0m Trial 149 finished with value: 0.9037902090797694 and parameters: {'lambda': 1.0131640022086625, 'max_depth': 9, 'n_estimators': 150}. Best is trial 119 with value: 0.9044345923015746.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=150, timeout=7200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e7d6655-3e3f-475b-b0cc-3307fc1750a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    lambda: 1.9519759861232213\n",
      "    max_depth: 9\n",
      "    n_estimators: 100\n"
     ]
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed7c1aa-a62f-4c3c-82fe-b75b5752054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict on test data\n",
    "# pd.DataFrame({\"id\":test_ids,\n",
    "#               \"target\":model.predict_proba(X_test)[:, 1]}).to_csv(\"../../submissions/May_2022/submission_XGB_MEstimator_encoding.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2535f9e1-154b-4f12-a08b-16dac1ac0350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions submit -c tabular-playground-series-may-2022 -f ../../submissions/May_2022/submission_XGB_MEstimator_encoding.csv -m \"XGBoost with Target Encoding Submission\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33892009-cd1b-410e-ac6f-2e0c711d3566",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Use the entire training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ee0cd5b-61f8-40c7-a05b-45ef2cc4c25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_train = pd.concat([X_train, X_valid, X_encode])\n",
    "final_y_train = pd.concat([y_train, y_valid, y_encode])\n",
    "\n",
    "model = XGBClassifier(**trial.params, use_label_encoder = False)\n",
    "\n",
    "final_model = model.fit(final_X_train, final_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a851f4c7-c179-4bb6-bb7e-380a05a55c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "pd.DataFrame({\"id\": test_ids,\n",
    "              \"target\":final_model.predict_proba(X_test)[:, 1]}).to_csv(\"../../submissions/May_2022/submission_XGB_target_encoding_full_fe.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3ccc99c-c848-4eb8-bc87-8c237c4107ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>900000</td>\n",
       "      <td>0.999554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>900001</td>\n",
       "      <td>0.969786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>900002</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>900003</td>\n",
       "      <td>0.044755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>900004</td>\n",
       "      <td>0.901859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699995</th>\n",
       "      <td>1599995</td>\n",
       "      <td>0.560077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699996</th>\n",
       "      <td>1599996</td>\n",
       "      <td>0.970752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699997</th>\n",
       "      <td>1599997</td>\n",
       "      <td>0.494648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699998</th>\n",
       "      <td>1599998</td>\n",
       "      <td>0.006546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699999</th>\n",
       "      <td>1599999</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id    target\n",
       "0        900000  0.999554\n",
       "1        900001  0.969786\n",
       "2        900002  0.000009\n",
       "3        900003  0.044755\n",
       "4        900004  0.901859\n",
       "...         ...       ...\n",
       "699995  1599995  0.560077\n",
       "699996  1599996  0.970752\n",
       "699997  1599997  0.494648\n",
       "699998  1599998  0.006546\n",
       "699999  1599999  0.000070\n",
       "\n",
       "[700000 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on test data\n",
    "pd.DataFrame({\"id\": test_ids,\n",
    "              \"target\":final_model.predict_proba(X_test)[:, 1]})#.to_csv(\"../../submissions/May_2022/submission_XGB_target_encoding_full.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce0820ca-c854-46fb-a4d3-7260ce7452ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12.5M/12.5M [00:06<00:00, 2.16MB/s]\n",
      "Successfully submitted to Tabular Playground Series - May 2022"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c tabular-playground-series-may-2022 -f ../../submissions/May_2022/submission_XGB_target_encoding_full_fe.csv -m \"XGBoost with Target Encoding Submission\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
